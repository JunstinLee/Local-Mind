---
[![Buy Me a Coffee](https://img.buymeacoffee.com/button-api/?text=Buy%20me%20a%20coffee&emoji=&slug=leejustin&button_colour=FFDD00&font_colour=000000&font_family=Cookie&outline_colour=000000&coffee_colour=ffffff)](https://www.buymeacoffee.com/leejustin)

**Local Mind** 是一款致力于稳定性、速度和可复现性的本地优先 RAG（检索增强生成）工具。它将用户数据完全存储在本地设备上，通过显式的工程流程读取和过滤文件信息。系统优先采用确定性算法回答问题，仅在必要时调用本地 AI，旨在为用户提供真实、可信的生产力提升。

**提示：“对于大型数据集，建议彻夜运行”**

## 功能特性

**一键部署与依赖管理**
*   提供完整的安装包（约 1.2GB），实现一键运行时环境配置。
*   内置 Embedding 模型下载器，可直接在应用内管理模型资源。
*   *注意：完整功能需要配合 Ollama 使用。*

**支持多种文件类型**：md, txt, log, html, pptx, pdf, docx

**显式工作流设计**
Local Mind 采用透明的“3+1”阶段工作流，拒绝黑盒操作：
1.  **文档准备模式**：“文件拷贝”按钮将目标文件物理隔离到准备区，确保仅处理用户授权的数据。
2.  **向量化**：
    *   支持一键构建知识库。
    *   **智能去重**：内置检查组件会自动识别并跳过已向量化的文件，避免冗余。
3.  **语义搜索模式**：基于本地 Embedding 模型，对向量化文件进行高精度语义匹配，快速定位目标。

**确定性优先的问答引擎**
系统通过工程手段处理绝大多数查询，**仅在必要时调用本地 AI**，以确保结果的精确性和可控性。回答格式会根据数据特征自动切换：
*   **表格**：当相关标题过多，或需要对日期、金额进行结构化汇总时触发。
*   **列表**：当涉及少量文件，或需要进行数值计算时触发。
*   **摘要**：当相关文件数量 $\le$ 3 时触发。

## 设计理念 (Philosophy)

*   **全流程掌控**
    用户有权决定如何分配时间和算力。Local Mind 拒绝静默的后台操作；所有高资源消耗任务（如向量化）均由用户手动触发。

*   **资产状态透明**
    文件是用户的核心资产。用户有权实时知晓文件是处于准备、向量化还是索引状态，拒绝数据处理的“黑盒”模式。

*   **拒绝不可控的自动化**
    **为什么仅在必要时调用本地 AI？**
    鉴于本地硬件和 AI 条件的限制，全自动的 RAG 工作流会导致完全不可控的响应时间和结果质量——这就像“一辆爆胎的汽车在高速公路上飞驰”，你永远不知道下一秒会发生什么。Local Mind 投入大量精力构建了一套工程系统，只为在特定条件下提供最稳定、基于事实的回答。

## 快速开始
  共有 3 种模式，每个标签页代表一种模式：
  
**文档准备模式**
<img width="1915" height="1007" alt="Docs" src="https://github.com/user-attachments/assets/09f899eb-e0f1-4aeb-8727-87b85129e33f" />


**搜索模式**
<img width="1919" height="1004" alt="Search" src="https://github.com/user-attachments/assets/becc80bd-b392-41e7-a3c2-6270a5dfa9a3" />

**问答模式**

<img width="1919" height="1003" alt="Q A" src="https://github.com/user-attachments/assets/526a79f1-64f0-4417-8dda-1d1d7b672d53" />



进入应用后，首先需要前往“设置”界面下载 Embedding 模型。

<img width="1911" height="1008" alt="First" src="https://github.com/user-attachments/assets/8294b6c0-cf95-4800-9abf-df8b8aefd993" />

下载完成后，点击“上传文件”按钮将文件拷贝到准备区。

<img width="1919" height="1002" alt="Second" src="https://github.com/user-attachments/assets/686c9088-9b7f-49ae-9f11-f9b6b75e3876" />


文件拷贝完成后，点击“构建知识库”按钮对文件进行向量化并导入知识库。

<img width="1919" height="1013" alt="thrid" src="https://github.com/user-attachments/assets/88faf4d3-f6cf-4b41-8a9d-53c5972fbeb0" />


构建完成后，即可放心使用搜索模式和问答模式。

## 使用场景

*   **海量文件快速检索**：经测试验证，可在 30 秒内从 265 个文件中精确过滤并定位到 200 个、70 个甚至仅 1 个相关目标文件。
*   **跨文档数据计算**：快速从多个文件的表格中提取金额数据，进行准确的聚合计算，并可追溯原始出处。
*   **按需 AI 介入**：
    *   定位到具体文件后，您可以手动要求 AI 提取特定内容。
    *   当系统生成的“摘要”不够详细时，您可以追问 AI 进行深度分析。
    *   当内容符合需求但存在语言障碍时，您可以指令 AI 进行翻译。

## 局限性与已知问题

1.  **向量化耗时**：目前向量化操作依赖 **CPU**。当文件数量或数据量较大时，处理时间较长（参考数据：在 32GB DDR5 内存环境下，向量化 230 个文件大约需要 30 分钟）。请合理规划您的处理时间。
2.  **网络状态判定**：系统通过 Ollama 接口信号而非实际服务加载完成状态来判定服务状态。因此，如果网络连接较差，即使模型已下载，也可能显示“未下载”。
3.  **文档准备区功能**：目前仅支持文件查看和基本过滤；暂不支持高级文件管理功能。
4.  **全量向量化**：目前不支持选择性地向量化准备区中的文件；进入准备区的所有文件默认都会被处理。请提前移除无关信息。
5.  **存储空间要求**：安装包大小约为 **1.2GB**。请确保有足够的磁盘空间。
6.  **语言支持**：目前支持 **简体中文、en-US 和 en-UK**；未来将添加更多语言。
7.  **文件拷贝进度不准**：文件拷贝进度条可能无法实时反映精确进度。请耐心等待。
8.  **向量化时间预估偏差**：预计向量化时间仅供参考。**请勿中途打断向量化**。在当前版本中，中断后需要从头开始处理未完成的文件，且无法完美断点续传。
9.  **Embedding 模型状态检测问题**：即使网络状况良好且 Embedding 模型已下载，点击设置界面有时仍可能提示下载模型。只需点击下载按钮并等待几秒钟，即可更新模型状态。
10. **搜索结果限制**：当搜索结果数量超过一定限制时，仅显示最相关的 20 条结果。
